{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # Works\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # Works\n",
    "from sklearn.neighbors import KNeighborsClassifier # Works\n",
    "from sklearn.naive_bayes import GaussianNB # Works\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "from imblearn.metrics import geometric_mean_score, make_index_balanced_accuracy, specificity_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import average\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, KMeansSMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids, CondensedNearestNeighbour, EditedNearestNeighbours, RandomUnderSampler\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "SEED = 42\n",
    "DATA_STRUCTURE = json.load(open('data_structure.json'))\n",
    "DATA_KEYS = list(DATA_STRUCTURE.keys())\n",
    "CLASSIFIERS = {\n",
    "  \"GaussianNB\":GaussianNB,\n",
    "  \"LinearDiscriminantAnalysis\":LinearDiscriminantAnalysis,\n",
    "  \"KNeighborsClassifier\":KNeighborsClassifier,\n",
    "  \"DecisionTreeClassifier\":DecisionTreeClassifier,\n",
    "  \"LogisticRegression\": LogisticRegression,\n",
    "  # \"SVC\":SVC\n",
    "  # Random forrest \n",
    "}\n",
    "OUTPUT_COLS = ['dataset', 'target', 'target_name', 'avg_precision', 'precision_folds', 'avg_recall', 'recall_folds', 'avg_f1', 'f1_folds', 'avg_geometric_mean', 'geometric_mean_folds','avg_specificity','specificity_folds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dataset   Target     value  chunk\n",
      "0    mushroom  target2  0.786322      0\n",
      "1       telco  target3  0.637090      0\n",
      "2        imdb  target2  0.567568      0\n",
      "3      census  target2  0.509846      0\n",
      "4        bank  target3  0.502913      0\n",
      "5       paris  target3  0.498800      0\n",
      "6       paris  target2  0.496300      0\n",
      "7     smoking  target2  0.484625      0\n",
      "8      census  target3  0.415984      0\n",
      "9      flight  target3  0.363326      0\n",
      "10      telco  target2  0.356348      1\n",
      "11    smoking  target1  0.347998      1\n",
      "12   mushroom  target3  0.346563      1\n",
      "13    smoking  target3  0.328425      1\n",
      "14      telco  target1  0.286163      1\n",
      "15       bank  target2  0.270227      1\n",
      "16     flight  target1  0.270035      1\n",
      "17     census  target1  0.264239      1\n",
      "18       imdb  target3  0.243511      1\n",
      "19      paris  target1  0.223200      1\n",
      "20  intention  target2  0.207192      2\n",
      "21     flight  target2  0.194529      2\n",
      "22       imdb  target1  0.187851      2\n",
      "23  intention  target3  0.185995      2\n",
      "24  intention  target1  0.173045      2\n",
      "25       bank  target1  0.126537      2\n",
      "26     anuran  target3  0.011814      2\n",
      "27     anuran  target2  0.010146      2\n",
      "28     anuran  target1  0.007366      2\n",
      "29   mushroom  target1  0.000000      2\n"
     ]
    }
   ],
   "source": [
    "complexityDF = pd.read_csv(f'./out/complexityDF.csv', index_col=0)\n",
    "\n",
    "complexityDFColumns = ['dataset','target1','target2', 'target3']\n",
    "complexityDF.columns = complexityDFColumns\n",
    "meltedComplexityDF = pd.melt(complexityDF, value_vars=['target1','target2', 'target3'], var_name='Target', id_vars=['dataset'])\n",
    "meltedComplexityDF= meltedComplexityDF.sort_values(by=['value'], ignore_index=True, ascending=False)\n",
    "chunks = np.array_split(meltedComplexityDF, 3)\n",
    "finalComplexityDF = pd.DataFrame({})\n",
    "for i, chunk in enumerate(chunks):\n",
    "  chunk['chunk'] = [i]*len(chunk)\n",
    "  labels = []\n",
    "  for i in range(len(chunk['Target'].values)):\n",
    "    labels.append(chunk['dataset'].values[i][0:3] + '_' +  chunk['Target'].values[i][-2:])\n",
    "  # print('------------------------------------------------')\n",
    "  finalComplexityDF = pd.concat((finalComplexityDF, chunk))\n",
    "print(finalComplexityDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(df, t1, t2, t3):\n",
    "\n",
    "  # print(t1.size)\n",
    "  # print(t2.size)\n",
    "  # print(t3)\n",
    "\n",
    "  df['t1'] = t1.tolist()\n",
    "  df['t2'] = t2.tolist()\n",
    "  df['t3'] = t3.tolist()\n",
    "\n",
    "  # use Seed\n",
    "  shuffledDf = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "  shuffledT1 = shuffledDf['t1']\n",
    "  shuffledT2 = shuffledDf['t2']\n",
    "  shuffledT3 = shuffledDf['t3']\n",
    "\n",
    "  shuffledDf = shuffledDf.drop(['t1','t2','t3'], 1)\n",
    "  return shuffledDf, shuffledT1, shuffledT2, shuffledT3\n",
    "\n",
    "def split(df, t1, t2, t3, k):\n",
    "  targets = np.vstack((t1, t2,t3)).T\n",
    "  chunks = np.array_split(df, k)\n",
    "  classes = np.array_split(targets, k)\n",
    "  return chunks, classes\n",
    "\n",
    "def combine(df,columns):\n",
    "  for col in columns:\n",
    "    df[col] = columns[col].tolist()\n",
    "  return df\n",
    "def initFoldResultObject():\n",
    "  return {\n",
    "    'target1' : {\n",
    "      'precScores': [],\n",
    "      'recallScores': [],\n",
    "      'f1Scores': [],\n",
    "      'geometricMeanScores': [],\n",
    "      'specificityScores': []\n",
    "    },\n",
    "    'target3' : {\n",
    "      'precScores': [],\n",
    "      'recallScores': [],\n",
    "      'f1Scores': [],\n",
    "      'geometricMeanScores': [],\n",
    "      'specificityScores': []\n",
    "    },\n",
    "    'target2' : {\n",
    "      'precScores': [],\n",
    "      'recallScores': [],\n",
    "      'f1Scores': [],\n",
    "      'geometricMeanScores': [],\n",
    "      'specificityScores': []\n",
    "    }\n",
    "}\n",
    "def get_data(name):\n",
    "  orderedcomplexity = finalComplexityDF[finalComplexityDF['dataset']==name].sort_values(by=['value'], ascending=False)['Target'].values\n",
    "  if name == 'imdb':\n",
    "    movie_data = pd.read_csv('./Datasets/movie_metadata.csv')\n",
    "    movie_data.drop_duplicates(inplace=True)\n",
    "    movie_data.loc[:,'genres'] = movie_data.loc[:,'genres'].apply(lambda x: x.split('|'))\n",
    "\n",
    "    genres = []\n",
    "    for x in movie_data.genres:\n",
    "      for g in x:\n",
    "        if g not in genres:\n",
    "          genres.append(g)\n",
    "\n",
    "    for g in genres:\n",
    "      movie_data.loc[:,g] = movie_data.loc[:,'genres'].apply(lambda x: int(g in x))\n",
    "\n",
    "    movie_data.drop([\"director_name\",\"actor_2_name\",\"movie_title\",\"genres\",\"actor_1_name\",\"actor_3_name\",\"plot_keywords\",\"movie_imdb_link\",\"cast_total_facebook_likes\"],axis=1, inplace = True)\n",
    "    movie_data.dropna(inplace=True)\n",
    "\n",
    "    movie_data[\"imdb_score\"] = movie_data[\"imdb_score\"].apply(float)\n",
    "    movie_data.loc[movie_data['imdb_score'].between(8,10), 'imdb_score'] = 100.0\n",
    "    movie_data.loc[movie_data['imdb_score'].between(5,7.99), 'imdb_score'] = 50.0\n",
    "    movie_data.loc[movie_data['imdb_score'].between(0,4.992), 'imdb_score'] = 30.0\n",
    "    movie_data[\"imdb_score\"] = movie_data[\"imdb_score\"].apply(str)\n",
    "    movie_data.loc[movie_data['imdb_score'] == \"100.0\", 'imdb_score'] = \"GOOD\"\n",
    "    movie_data.loc[movie_data['imdb_score'] == \"50.0\", 'imdb_score'] = \"AVERAGE\"\n",
    "    movie_data.loc[movie_data['imdb_score'] == \"30.0\", 'imdb_score'] = \"BAD\"\n",
    "\n",
    "    ratings = movie_data[\"content_rating\"].unique()\n",
    "    for rate in ratings:\n",
    "        if rate == \"M\":\n",
    "            movie_data.loc[movie_data['content_rating'] == rate, 'content_rating'] = \"PG\"\n",
    "        elif rate == \"GP\":\n",
    "            movie_data.loc[movie_data['content_rating'] == rate, 'content_rating'] = \"PG\"\n",
    "        elif rate == \"Unrated\":\n",
    "            movie_data.loc[movie_data['content_rating'] == rate, 'content_rating'] = \"Not Rated\"\n",
    "        elif rate == \"Passed\":\n",
    "            movie_data.loc[movie_data['content_rating'] == rate, 'content_rating'] = \"Approved\"\n",
    "        elif rate == \"X\":\n",
    "            movie_data.loc[movie_data['content_rating'] == rate, 'content_rating'] = \"NC-17\"\n",
    "\n",
    "    movie_data.loc[movie_data['gross'].between(0,15000000.0), 'gross'] = 0.0\n",
    "    movie_data.loc[movie_data['gross'].between(1500000.01,762000000.0), 'gross'] = 1.0\n",
    "    movie_data = pd.get_dummies(movie_data,columns=['color','language','country'],drop_first=True)\n",
    "\n",
    "    target1 = le.fit_transform(movie_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(movie_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(movie_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    \n",
    "    X_final = movie_data.drop([\"imdb_score\", \"content_rating\", \"gross\"],axis=1)\n",
    "\n",
    "  elif name == 'mushroom':\n",
    "    mushroom_data = pd.read_csv('./Datasets/mushroom.csv')\n",
    "    mushroom_data = mushroom_data[mushroom_data['stalk-root']!='?']\n",
    "    mushroom_data = pd.get_dummies(mushroom_data,columns=['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
    "          'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
    "          'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "          'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
    "          'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
    "          'ring-type', 'spore-print-color'],drop_first=True)\n",
    "    target1 = le.fit_transform(mushroom_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(mushroom_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(mushroom_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = mushroom_data.drop([\"Class\", \"population\", \"habitat\"],axis=1)\n",
    "  \n",
    "  elif name == 'census':\n",
    "    census_data = pd.read_csv('./Datasets/census.csv',names=['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','income']) \n",
    "    census_data=census_data.drop_duplicates()\n",
    "    for col in census_data.columns:\n",
    "      census_data = census_data[census_data[col]!=' ?']\n",
    "    census_data.loc[census_data.income==' <=50K.','income'] = ' <=50K' \n",
    "    census_data.loc[census_data.income==' >50K.','income'] = ' >50K'\n",
    "    census_data = pd.get_dummies(census_data,columns=['education','occupation','relationship','race','sex','native-country'],drop_first=True)\n",
    "    target1 = le.fit_transform(census_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(census_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(census_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = census_data.drop([\"income\", \"marital-status\", \"workclass\"],axis=1)\n",
    "  \n",
    "  elif name == 'bank':\n",
    "    bank_data = pd.read_csv('./Datasets/bank-additional.csv')\n",
    "    for col in bank_data.columns:\n",
    "      bank_data = bank_data[bank_data[col]!='unknown']\n",
    "    bank_data = pd.get_dummies(bank_data,columns=['job','education','default','contact','month','day_of_week','poutcome','marital'],drop_first=True)\n",
    "    target1 = le.fit_transform(bank_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(bank_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(bank_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = bank_data.drop([\"y\", \"loan\", \"housing\"],axis=1)\n",
    "\n",
    "  elif name == 'intention':\n",
    "    intention_data = pd.read_csv('./Datasets/online_shoppers_intention.csv')\n",
    "    intention_data = intention_data.drop_duplicates()\n",
    "    intention_data = intention_data[intention_data['VisitorType']!='Other']\n",
    "    intention_data = pd.get_dummies(intention_data,columns=['Month','Weekend'],drop_first=True)        \n",
    "    target1 = le.fit_transform(intention_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(intention_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(intention_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = intention_data.drop([\"Revenue\", \"VisitorType\", \"SpecialDay\"],axis=1)\n",
    "\n",
    "  elif name == 'anuran':\n",
    "    anuran_data = pd.read_csv('./Datasets/Frogs_MFCCs.csv')\n",
    "    anuran_data.drop(columns='RecordID',inplace=True)\n",
    "    target1 = le.fit_transform(anuran_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(anuran_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(anuran_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = anuran_data.drop([\"Family\", \"Genus\", \"Species\"],axis=1)\n",
    "  \n",
    "  elif name == 'telco':\n",
    "    telco_data = pd.read_csv('./Datasets/telco.csv')\n",
    "    telco_data.drop(columns=['customerID'],inplace=True)\n",
    "    telco_data = telco_data.drop_duplicates()\n",
    "    telco_data = telco_data[telco_data.TotalCharges!=' ']\n",
    "    telco_data = pd.get_dummies(telco_data,columns=['gender','Partner','Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling'],drop_first=True)\n",
    "    target1 = le.fit_transform(telco_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(telco_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(telco_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = telco_data.drop([\"Churn\", \"Contract\", \"PaymentMethod\"],axis=1)\n",
    "\n",
    "  elif name == 'paris':\n",
    "    paris_data = pd.read_csv('./Datasets/ParisHousingClass.csv')\n",
    "    paris_data.drop(columns='made',inplace=True)\n",
    "    target1 = le.fit_transform(paris_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(paris_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(paris_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = paris_data.drop([\"category\", \"isNewBuilt\", \"hasStorageRoom\"],axis=1)\n",
    "  \n",
    "  elif name == 'smoking':\n",
    "    smoking_data = pd.read_csv('./Datasets/smoking.csv')\n",
    "    smoking_data.drop(columns=['ID','oral'],inplace=True)\n",
    "    smoking_data = smoking_data.drop_duplicates()\n",
    "    smoking_data = pd.get_dummies(smoking_data,columns=['gender'],drop_first=True)\n",
    "    target1 = le.fit_transform(smoking_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(smoking_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(smoking_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = smoking_data.drop([\"smoking\", \"tartar\", \"dental caries\"],axis=1)\n",
    "  \n",
    "  elif name == 'flight':\n",
    "    flight_data = pd.read_csv('./Datasets/flight.csv')\n",
    "    flight_data.dropna(inplace=True)\n",
    "    flight_data = pd.get_dummies(flight_data,columns=['Gender','Type of Travel'],drop_first=True)\n",
    "    target1 = le.fit_transform(flight_data[DATA_STRUCTURE[name][orderedcomplexity[0]]])\n",
    "    target2 = le.fit_transform(flight_data[DATA_STRUCTURE[name][orderedcomplexity[1]]])\n",
    "    target3 = le.fit_transform(flight_data[DATA_STRUCTURE[name][orderedcomplexity[2]]])\n",
    "    X_final = flight_data.drop([\"satisfaction\", \"Customer Type\", \"Class\"],axis=1)\n",
    "  \n",
    "  else:\n",
    "    raise ValueError('Incorrect dataset')\n",
    "  \n",
    "  return X_final, target1, target2, target3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import average\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Because Scikit-learn's multi output classifier doesn't support metrics for multi label classification, we implemented our own.\n",
    "def crossValidate(classifier, df, t1, t2, t3, k, dataSetName):\n",
    "  df, t1, t2, t3 = shuffle(df, t1, t2, t3)\n",
    "  # Split the data and classes into k subsets\n",
    "  data, classes = split(df, t1, t2, t3, k)\n",
    "  foldResults = {\n",
    "    'target1' : {\n",
    "      'precScores': [],\n",
    "      'recallScores': [],\n",
    "      'f1Scores': [],\n",
    "      'geometricMeanScores': [],\n",
    "      'specificityScores': []\n",
    "      \n",
    "    },\n",
    "    'target3' : {\n",
    "      'precScores': [],\n",
    "      'recallScores': [],\n",
    "      'f1Scores': [],\n",
    "      'geometricMeanScores': [],\n",
    "      'specificityScores': []\n",
    "    },\n",
    "    'target2' : {\n",
    "      'precScores': [],\n",
    "      'recallScores': [],\n",
    "      'f1Scores': [],\n",
    "      'geometricMeanScores': [],\n",
    "      'specificityScores': []\n",
    "    }\n",
    "  }\n",
    "\n",
    "  for i in range(k):\n",
    "    # use the data at position i as the test data\n",
    "    testData = data[i]\n",
    "    testClasses = classes[i]\n",
    "\n",
    "    # use the data at all positions other than i as the train data\n",
    "    trainData = pd.concat((data[:i] + data[i+1:]))\n",
    "    trainclasses = np.concatenate((classes[:i] + classes[i+1:]))\n",
    "    \n",
    "    # Create a multioutput classifier from the provided classifier\n",
    "    clf = MultiOutputClassifier(classifier())\n",
    "\n",
    "\n",
    "\n",
    "    # Fit the model to Training data\n",
    "    clf.fit(trainData, trainclasses)\n",
    "\n",
    "    # Use the model on the test data\n",
    "    testResults = clf.predict(X=testData)\n",
    "\n",
    "    # Since the results for multi label classification come as a list of size (n, 3), decompose the list into the results for each target\n",
    "    t1Results = testResults[:, 0]\n",
    "    t2Results = testResults[:, 1]\n",
    "    t3Results = testResults[:, 2]\n",
    "\n",
    "    # Do the same for the actual classes\n",
    "    t1Classes = testClasses[:, 0]\n",
    "    t2Classes = testClasses[:, 1]\n",
    "    t3Classes = testClasses[:, 2]\n",
    "\n",
    "    actualVsPredicted = {\n",
    "      'target1':(t1Classes, t1Results),\n",
    "      'target2':(t2Classes, t2Results),\n",
    "      'target3':(t3Classes, t3Results)\n",
    "    }\n",
    "    for target in actualVsPredicted:\n",
    "      (actual, predicted) = actualVsPredicted[target]\n",
    "      # Calculate the scores for each metric\n",
    "      prec_macro = precision_score(actual, predicted, average='macro', zero_division=0)\n",
    "      recall_macro = recall_score(actual, predicted, average=\"macro\", zero_division=0)\n",
    "      f1_macro = f1_score(actual, predicted, average='macro')\n",
    "      geometric_mean = geometric_mean_score(actual, predicted)\n",
    "      specificity = specificity_score(actual, predicted, average='macro')\n",
    "\n",
    "      # Add the scores for the current train/test split to the list of other scores for the respective target\n",
    "      foldResults[target]['precScores'].append(prec_macro)\n",
    "      foldResults[target]['recallScores'].append(recall_macro)\n",
    "      foldResults[target]['f1Scores'].append(f1_macro)\n",
    "      foldResults[target]['geometricMeanScores'].append(geometric_mean)\n",
    "      foldResults[target]['specificityScores'].append(specificity)\n",
    "  \n",
    "\n",
    "  df = pd.DataFrame(columns=OUTPUT_COLS)\n",
    "  for target in foldResults:\n",
    "    stats = foldResults[target]\n",
    "    row = [dataSetName, target,DATA_STRUCTURE[dataSetName][target]]\n",
    "    for stat in stats:\n",
    "      row.append(average(stats[stat]))\n",
    "      row.append(stats[stat])\n",
    "    pdRow = pd.DataFrame(row).T\n",
    "    pdRow.columns = OUTPUT_COLS\n",
    "    df = pd.concat([df,pdRow], axis=0, ignore_index=True)\n",
    "  return df\n",
    "\n",
    "aggregateMetrics = {}\n",
    "\n",
    "for name in CLASSIFIERS:\n",
    "  print(name+ ': Starting')\n",
    "  outputDf = pd.DataFrame()\n",
    "  for i in range(len(DATA_STRUCTURE)):\n",
    "    if i < 80:\n",
    "      print('   '+ DATA_KEYS[i] + ': starting')\n",
    "      df, target1, target2, target3 = get_data(DATA_KEYS[i] )\n",
    "      outputDf = pd.concat([outputDf, crossValidate(CLASSIFIERS[name],df, target1, target2, target3, 5, DATA_KEYS[i])], ignore_index=True)\n",
    "    # print(outputDf)\n",
    "  print(name+ ': done')\n",
    "  print('The average of each metric after cross validation per target across all data sets')\n",
    "  result = outputDf.groupby('target')['avg_precision', 'avg_recall', 'avg_f1', 'avg_geometric_mean','avg_specificity'].mean()\n",
    "  print(result)\n",
    "  aggregateMetrics[name] = result\n",
    "  outputDf.to_csv(path_or_buf=f'./out/sorted-descending-complexity/original/{name}.csv')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Imbalance for Target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "GaussianNB: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "LinearDiscriminantAnalysis: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "LinearDiscriminantAnalysis: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "KNeighborsClassifier: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "KNeighborsClassifier: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "DecisionTreeClassifier: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "DecisionTreeClassifier: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "LogisticRegression: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "LogisticRegression: done\n",
      "The average of each metric after cross validation per target across all data sets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x4000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "plt.figure(figsize=(20, 50), dpi=80)\n",
    "def crossValidateSmote(classifier, df, t1, t2, t3, k, dataSetName):\n",
    "  \n",
    "  df, t1, t2, t3 = shuffle(df, t1, t2, t3)\n",
    "  data, classes = split(df, t1, t2, t3, k)\n",
    "  foldResults = initFoldResultObject()\n",
    "\n",
    "  for i in range(k):\n",
    "    # use the data at position i as the test data\n",
    "    testData = data[i]\n",
    "    testClasses = classes[i]\n",
    "\n",
    "    # use the data at all positions other than i as the train data\n",
    "    trainData = pd.concat((data[:i] + data[i+1:]))\n",
    "    trainClasses = np.concatenate((classes[:i] + classes[i+1:]))\n",
    "\n",
    "    # Add target2 and target3 as features to the dataframe for Oversampling of target1\n",
    "    testDataCombined = combine(trainData, {'t2': trainClasses[:, 1], 't3':trainClasses[:, 2]})\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    sm = SMOTE(random_state=SEED, sampling_strategy='not majority')\n",
    "    reSampled_df, resampled_target1 = sm.fit_resample(testDataCombined, trainClasses[:, 0])\n",
    "\n",
    "    # Build the training outpus classes using the resampled target1 values (generated as classes), and the target2 and target3 values (generated as features) from smote \n",
    "    resampledTrainClasses = np.vstack((resampled_target1, reSampled_df['t2'], reSampled_df['t3'])).T\n",
    "    reSampled_df = reSampled_df.drop(['t2','t3'], 1)\n",
    "  \n",
    "    # Create and fit a multioutput classifier from the provided classifier\n",
    "    clf = MultiOutputClassifier(classifier())\n",
    "    clf.fit(reSampled_df, resampledTrainClasses)\n",
    "\n",
    "    # Use the model on the test data\n",
    "    testResults = clf.predict(X=testData)\n",
    "\n",
    "    actualVsPredicted = {\n",
    "      'target1':(testClasses[:, 0],  testResults[:, 0]),\n",
    "      'target2':(testClasses[:, 1], testResults[:, 1]),\n",
    "      'target3':(testClasses[:, 2], testResults[:, 2])\n",
    "    }\n",
    "\n",
    "    for target in actualVsPredicted:\n",
    "      (actual, predicted) = actualVsPredicted[target]\n",
    "      # Add the scores for the current train/test split to the list of other scores for the respective target\n",
    "      foldResults[target]['precScores'].append(precision_score(actual, predicted, average='macro', zero_division=0))\n",
    "      foldResults[target]['recallScores'].append(recall_score(actual, predicted, average=\"macro\", zero_division=0))\n",
    "      foldResults[target]['f1Scores'].append(f1_score(actual, predicted, average='macro'))\n",
    "      foldResults[target]['geometricMeanScores'].append(geometric_mean_score(actual, predicted))\n",
    "      foldResults[target]['specificityScores'].append(specificity_score(actual, predicted, average='macro'))\n",
    "\n",
    "  df = pd.DataFrame(columns=OUTPUT_COLS)\n",
    "  for target in foldResults:\n",
    "    stats = foldResults[target]\n",
    "    row = [dataSetName,target, DATA_STRUCTURE[dataSetName][target]]\n",
    "    for stat in stats:\n",
    "      row.append(average(stats[stat]))\n",
    "      row.append(stats[stat])\n",
    "    pdRow = pd.DataFrame(row).T\n",
    "    pdRow.columns = OUTPUT_COLS\n",
    "    df = pd.concat([df,pdRow], axis=0, ignore_index=True)\n",
    "  return df\n",
    "\n",
    "aggregateMetricsAdjusted = {}\n",
    "for name in CLASSIFIERS:\n",
    "  print(name+ ': Starting')\n",
    "  outputDf = pd.DataFrame()\n",
    "  for i in range(len(DATA_STRUCTURE)):\n",
    "    print('   '+ DATA_KEYS[i] + ': starting')\n",
    "    df, target1, target2, target3 = get_data(DATA_KEYS[i])\n",
    "    outputDf = pd.concat([outputDf, crossValidateSmote(CLASSIFIERS[name],df, target1, target2, target3, 5, DATA_KEYS[i])], ignore_index=True)\n",
    "    # print(outputDf)\n",
    "    \n",
    "  print(name+ ': done')\n",
    "  print('The average of each metric after cross validation per target across all data sets')\n",
    "  result = outputDf.groupby('target')['avg_precision', 'avg_recall', 'avg_f1', 'avg_geometric_mean', 'avg_specificity'].mean()\n",
    "  aggregateMetricsAdjusted[name] = result\n",
    "  outputDf.to_csv(path_or_buf=f'./out/sorted-decreasing-complexity/balanced-target1/{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Imbalance for Target1 and target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "GaussianNB: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "LinearDiscriminantAnalysis: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "LinearDiscriminantAnalysis: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "KNeighborsClassifier: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "KNeighborsClassifier: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "DecisionTreeClassifier: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "DecisionTreeClassifier: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "LogisticRegression: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "LogisticRegression: done\n",
      "The average of each metric after cross validation per target across all data sets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x4000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "plt.figure(figsize=(20, 50), dpi=80)\n",
    "def crossValidateSmote(classifier, df, t1, t2, t3, k, dataSetName):\n",
    "  \n",
    "  df, t1, t2, t3 = shuffle(df, t1, t2, t3)\n",
    "  data, classes = split(df, t1, t2, t3, k)\n",
    "  foldResults = initFoldResultObject()\n",
    "\n",
    "  for i in range(k):\n",
    "    # use the data at position i as the test data\n",
    "    testData = data[i]\n",
    "    testClasses = classes[i]\n",
    "\n",
    "    # use the data at all positions other than i as the train data\n",
    "    trainData = pd.concat((data[:i] + data[i+1:]))\n",
    "    trainClasses = np.concatenate((classes[:i] + classes[i+1:]))\n",
    "\n",
    "    # Add target2 and target3 as features to the dataframe for Oversampling of target1\n",
    "    testDataCombined = combine(trainData, {'t2': trainClasses[:, 1], 't3':trainClasses[:, 2]})\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    sm = SMOTE(random_state=SEED, sampling_strategy='not majority')\n",
    "\n",
    "\n",
    "    reSampled_df_t1, reSampled_t1_target1 = sm.fit_resample(testDataCombined, trainClasses[:, 0])\n",
    "    reSampled_df_t1['t1'] = reSampled_t1_target1\n",
    "    reSampled_df_t1_classes = np.vstack((reSampled_t1_target1, reSampled_df_t1['t2'], reSampled_df_t1['t3'])).T\n",
    "\n",
    "\n",
    "    #remove target 2 from the features before oversampling for target 2\n",
    "    reSampled_df_t1_target2 = reSampled_df_t1['t2']\n",
    "    reSampled_df_t1 = reSampled_df_t1.drop(['t2'], 1)\n",
    "\n",
    "    reSampled_df_t1_t2, reSampled_t1_t2_target2 = sm.fit_resample(reSampled_df_t1, reSampled_df_t1_target2)\n",
    "    reSampled_df_t1_t2_classes = np.vstack((reSampled_df_t1_t2['t1'], reSampled_t1_t2_target2, reSampled_df_t1_t2['t3'])).T\n",
    "    reSampled_df_t1_t2 = reSampled_df_t1_t2.drop(['t1','t3'], 1)\n",
    "  \n",
    "    # Create and fit a multioutput classifier from the provided classifier\n",
    "    clf = MultiOutputClassifier(classifier())\n",
    "    clf.fit(reSampled_df_t1_t2, reSampled_df_t1_t2_classes)\n",
    "\n",
    "    # Use the model on the test data\n",
    "    testResults = clf.predict(X=testData)\n",
    "\n",
    "    actualVsPredicted = {\n",
    "      'target1':(testClasses[:, 0],  testResults[:, 0]),\n",
    "      'target2':(testClasses[:, 1], testResults[:, 1]),\n",
    "      'target3':(testClasses[:, 2], testResults[:, 2])\n",
    "    }\n",
    "\n",
    "    for target in actualVsPredicted:\n",
    "      (actual, predicted) = actualVsPredicted[target]\n",
    "      # Add the scores for the current train/test split to the list of other scores for the respective target\n",
    "      foldResults[target]['precScores'].append(precision_score(actual, predicted, average='macro', zero_division=0))\n",
    "      foldResults[target]['recallScores'].append(recall_score(actual, predicted, average=\"macro\", zero_division=0))\n",
    "      foldResults[target]['f1Scores'].append(f1_score(actual, predicted, average='macro'))\n",
    "      foldResults[target]['geometricMeanScores'].append(geometric_mean_score(actual, predicted))\n",
    "      foldResults[target]['specificityScores'].append(specificity_score(actual, predicted, average='macro'))\n",
    "\n",
    "  df = pd.DataFrame(columns=OUTPUT_COLS)\n",
    "  for target in foldResults:\n",
    "    stats = foldResults[target]\n",
    "    row = [dataSetName,target, DATA_STRUCTURE[dataSetName][target]]\n",
    "    for stat in stats:\n",
    "      row.append(average(stats[stat]))\n",
    "      row.append(stats[stat])\n",
    "    pdRow = pd.DataFrame(row).T\n",
    "    pdRow.columns = OUTPUT_COLS\n",
    "    df = pd.concat([df,pdRow], axis=0, ignore_index=True)\n",
    "  return df\n",
    "\n",
    "aggregateMetricsAdjusted = {}\n",
    "for name in CLASSIFIERS:\n",
    "  print(name+ ': Starting')\n",
    "  outputDf = pd.DataFrame()\n",
    "  for i in range(len(DATA_STRUCTURE)):\n",
    "    print('   '+ DATA_KEYS[i] + ': starting')\n",
    "    df, target1, target2, target3 = get_data(DATA_KEYS[i])\n",
    "    outputDf = pd.concat([outputDf, crossValidateSmote(CLASSIFIERS[name],df, target1, target2, target3, 5, DATA_KEYS[i])], ignore_index=True)\n",
    "    # print(outputDf)\n",
    "    \n",
    "  print(name+ ': done')\n",
    "  print('The average of each metric after cross validation per target across all data sets')\n",
    "  result = outputDf.groupby('target')['avg_precision', 'avg_recall', 'avg_f1', 'avg_geometric_mean', 'avg_specificity'].mean()\n",
    "  aggregateMetricsAdjusted[name] = result\n",
    "  outputDf.to_csv(path_or_buf=f'./out/sorted-decreasing-complexity/balanced-target1-target2/{name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Imbalance for Target1, Target3, and Target3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "GaussianNB: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "LinearDiscriminantAnalysis: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "LinearDiscriminantAnalysis: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "KNeighborsClassifier: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "KNeighborsClassifier: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "DecisionTreeClassifier: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "DecisionTreeClassifier: done\n",
      "The average of each metric after cross validation per target across all data sets\n",
      "LogisticRegression: Starting\n",
      "   imdb: starting\n",
      "   mushroom: starting\n",
      "   census: starting\n",
      "   bank: starting\n",
      "   intention: starting\n",
      "   anuran: starting\n",
      "   telco: starting\n",
      "   paris: starting\n",
      "   smoking: starting\n",
      "   flight: starting\n",
      "LogisticRegression: done\n",
      "The average of each metric after cross validation per target across all data sets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x4000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "plt.figure(figsize=(20, 50), dpi=80)\n",
    "def crossValidateSmote(classifier, df, t1, t2, t3, k, dataSetName):\n",
    "  \n",
    "  df, t1, t2, t3 = shuffle(df, t1, t2, t3)\n",
    "  data, classes = split(df, t1, t2, t3, k)\n",
    "  foldResults = initFoldResultObject()\n",
    "\n",
    "  for i in range(k):\n",
    "    # use the data at position i as the test data\n",
    "    testData = data[i]\n",
    "    testClasses = classes[i]\n",
    "\n",
    "    # use the data at all positions other than i as the train data\n",
    "    trainData = pd.concat((data[:i] + data[i+1:]))\n",
    "    trainClasses = np.concatenate((classes[:i] + classes[i+1:]))\n",
    "\n",
    "    # Add target2 and target3 as features to the dataframe for Oversampling of target1\n",
    "    testDataCombined = combine(trainData, {'t2': trainClasses[:, 1], 't3':trainClasses[:, 2]})\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    sm = SMOTE(random_state=SEED, sampling_strategy='not majority')\n",
    "\n",
    "\n",
    "    reSampled_df_t1, reSampled_t1_target1 = sm.fit_resample(testDataCombined, trainClasses[:, 0])\n",
    "    reSampled_df_t1['t1'] = reSampled_t1_target1\n",
    "    reSampled_df_t1_classes = np.vstack((reSampled_t1_target1, reSampled_df_t1['t2'], reSampled_df_t1['t3'])).T\n",
    "\n",
    "\n",
    "    #remove target 2 from the features before oversampling for target 2\n",
    "    reSampled_df_t1_target2 = reSampled_df_t1['t2']\n",
    "    reSampled_df_t1 = reSampled_df_t1.drop(['t2'], 1)\n",
    "    reSampled_df_t1_t2, reSampled_t1_t2_target2 = sm.fit_resample(reSampled_df_t1, reSampled_df_t1_target2)\n",
    "    reSampled_df_t1_t2_classes = np.vstack((reSampled_df_t1_t2['t1'], reSampled_t1_t2_target2, reSampled_df_t1_t2['t3'])).T\n",
    "\n",
    "    # Add the resampled target values to the attribute dataset\n",
    "    reSampled_df_t1_t2['t2'] = reSampled_t1_t2_target2\n",
    "\n",
    "    #remove target 3 from the features before oversampling for target 3\n",
    "    reSampled_df_t1_t2_target3 = reSampled_df_t1_t2['t3']\n",
    "    reSampled_df_t1_t2 = reSampled_df_t1_t2.drop(['t3'], 1)\n",
    "    reSampled_df_t1_t2_t3, reSampled_t1_t2_t3_target3 = sm.fit_resample(reSampled_df_t1_t2, reSampled_df_t1_t2_target3)\n",
    "    reSampled_df_t1_t2_t3_classes = np.vstack((reSampled_df_t1_t2_t3['t1'], reSampled_df_t1_t2_t3['t2'], reSampled_t1_t2_t3_target3)).T\n",
    "    \n",
    "    reSampled_df_t1_t2_t3 = reSampled_df_t1_t2_t3.drop(['t1','t2'], 1)\n",
    "\n",
    "    # Create and fit a multioutput classifier from the provided classifier\n",
    "    clf = MultiOutputClassifier(classifier())\n",
    "    clf.fit(reSampled_df_t1_t2_t3, reSampled_df_t1_t2_t3_classes)\n",
    "\n",
    "    # Use the model on the test data\n",
    "    testResults = clf.predict(X=testData)\n",
    "\n",
    "    actualVsPredicted = {\n",
    "      'target1':(testClasses[:, 0],  testResults[:, 0]),\n",
    "      'target2':(testClasses[:, 1], testResults[:, 1]),\n",
    "      'target3':(testClasses[:, 2], testResults[:, 2])\n",
    "    }\n",
    "\n",
    "    for target in actualVsPredicted:\n",
    "      (actual, predicted) = actualVsPredicted[target]\n",
    "      # Add the scores for the current train/test split to the list of other scores for the respective target\n",
    "      foldResults[target]['precScores'].append(precision_score(actual, predicted, average='macro', zero_division=0))\n",
    "      foldResults[target]['recallScores'].append(recall_score(actual, predicted, average=\"macro\", zero_division=0))\n",
    "      foldResults[target]['f1Scores'].append(f1_score(actual, predicted, average='macro'))\n",
    "      foldResults[target]['geometricMeanScores'].append(geometric_mean_score(actual, predicted))\n",
    "      foldResults[target]['specificityScores'].append(specificity_score(actual, predicted, average='macro'))\n",
    "\n",
    "  df = pd.DataFrame(columns=OUTPUT_COLS)\n",
    "  for target in foldResults:\n",
    "    stats = foldResults[target]\n",
    "    row = [dataSetName,target, DATA_STRUCTURE[dataSetName][target]]\n",
    "    for stat in stats:\n",
    "      row.append(average(stats[stat]))\n",
    "      row.append(stats[stat])\n",
    "    pdRow = pd.DataFrame(row).T\n",
    "    pdRow.columns = OUTPUT_COLS\n",
    "    df = pd.concat([df,pdRow], axis=0, ignore_index=True)\n",
    "  return df\n",
    "\n",
    "aggregateMetricsAdjusted = {}\n",
    "for name in CLASSIFIERS:\n",
    "  print(name+ ': Starting')\n",
    "  outputDf = pd.DataFrame()\n",
    "  for i in range(len(DATA_STRUCTURE)):\n",
    "    print('   '+ DATA_KEYS[i] + ': starting')\n",
    "    df, target1, target2, target3 = get_data(DATA_KEYS[i])\n",
    "    outputDf = pd.concat([outputDf, crossValidateSmote(CLASSIFIERS[name],df, target1, target2, target3, 5, DATA_KEYS[i])], ignore_index=True)\n",
    "    # print(outputDf)\n",
    "    \n",
    "  print(name+ ': done')\n",
    "  print('The average of each metric after cross validation per target across all data sets')\n",
    "  result = outputDf.groupby('target')['avg_precision', 'avg_recall', 'avg_f1', 'avg_geometric_mean', 'avg_specificity'].mean()\n",
    "  aggregateMetricsAdjusted[name] = result\n",
    "  outputDf.to_csv(path_or_buf=f'./out/sorted-decreasing-complexity/balanced-target1-target2-target3/{name}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('csi4900')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11c5f941b3679d86a3337c94acfde891d9c2e84f639f121f0c3784daecf41f4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
